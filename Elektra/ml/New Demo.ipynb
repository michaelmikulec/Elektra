{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt, iirnotch\n",
    "from tqdm import tqdm\n",
    "import mne\n",
    "\n",
    "# === Paths ===\n",
    "EEG_DIR = \"C:/Users/Kevin Tran/Documents/GitHub ED1/hms-harmful-brain-activity-classificationtrain_eegs/train_eegs\"\n",
    "PROCESSED_EEG_DIR = \"C:/Users/Kevin Tran/Documents/Project Data/processed eegs2\"\n",
    "os.makedirs(PROCESSED_EEG_DIR, exist_ok=True)\n",
    "\n",
    "# === Sampling Rate ===\n",
    "FS = 200  # Hz\n",
    "\n",
    "# === Preprocessing Functions ===\n",
    "def apply_notch_filter(signal, fs=FS, freq=60.0, quality_factor=30):\n",
    "    b, a = iirnotch(w0=freq, Q=quality_factor, fs=fs)\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "def apply_bandpass_filter(signal, fs=FS, lowcut=0.5, highcut=40.0, order=5):\n",
    "    nyquist = 0.5 * fs\n",
    "    low, high = lowcut / nyquist, highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "def normalize_signal(signal):\n",
    "    return (signal - np.mean(signal)) / np.std(signal)\n",
    "\n",
    "def apply_ica(signal_df, fs=FS, n_components=10):\n",
    "    try:\n",
    "        n_components = min(n_components, len(signal_df.columns))\n",
    "        info = mne.create_info(ch_names=list(signal_df.columns), sfreq=fs, ch_types=[\"eeg\"] * len(signal_df.columns))\n",
    "        raw = mne.io.RawArray(signal_df.values.T, info)\n",
    "        raw.filter(l_freq=1.0, h_freq=None)\n",
    "        ica = mne.preprocessing.ICA(n_components=n_components, random_state=42, max_iter=\"auto\")\n",
    "        ica.fit(raw)\n",
    "        raw_clean = ica.apply(raw)\n",
    "        return pd.DataFrame(raw_clean.get_data().T, columns=signal_df.columns)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è ICA failed: {e}\")\n",
    "        return signal_df\n",
    "\n",
    "# === Process Each File ===\n",
    "eeg_files = [f for f in os.listdir(EEG_DIR) if f.endswith(\".parquet\")]\n",
    "saved_count = 0\n",
    "\n",
    "for idx, file_name in tqdm(enumerate(eeg_files), total=len(eeg_files), desc=\"Preprocessing 10s center EEG segments\"):\n",
    "    eeg_id = file_name.replace(\".parquet\", \"\")\n",
    "    eeg_path = os.path.join(EEG_DIR, file_name)\n",
    "\n",
    "    try:\n",
    "        df = pd.read_parquet(eeg_path)\n",
    "        if df.shape[0] < FS * 50:\n",
    "            print(f\"‚ö†Ô∏è Skipping {eeg_id}: File too short ({df.shape})\")\n",
    "            continue\n",
    "\n",
    "        # Extract 10s from center (20s‚Äì30s of 50s window)\n",
    "        start = 20 * FS\n",
    "        end = start + 10 * FS\n",
    "        segment = df.iloc[start:end].copy()\n",
    "\n",
    "        # Preprocess\n",
    "        for ch in segment.columns:\n",
    "            segment[ch] = normalize_signal(apply_bandpass_filter(apply_notch_filter(segment[ch].values)))\n",
    "\n",
    "        segment = apply_ica(segment)\n",
    "\n",
    "        # Save\n",
    "        output_path = os.path.join(PROCESSED_EEG_DIR, f\"{eeg_id}_10s.parquet\")\n",
    "        segment.to_parquet(output_path)\n",
    "        saved_count += 1\n",
    "        print(f\"‚úÖ Saved: {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed on {eeg_id}: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Done. Total saved 10s segments: {saved_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drops EKG During Feature Extraction\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Paths ===\n",
    "PROCESSED_EEG_DIR = \"C:/Users/Kevin Tran/Documents/Project Data/processed eegs2\"\n",
    "OUTPUT_FEATURES_CSV = \"C:/Users/Kevin Tran/Documents/Project Data/eeg_extracted_features.csv\"\n",
    "FS = 200  # Hz\n",
    "\n",
    "# === EEG Frequency Bands ===\n",
    "BANDS = {\n",
    "    \"delta\": (1, 3), \"theta\": (4, 7), \"alpha1\": (8, 9), \"alpha2\": (10, 12),\n",
    "    \"beta1\": (13, 17), \"beta2\": (18, 30), \"gamma1\": (31, 40), \"gamma2\": (41, 50), \"higher\": (51, 100)\n",
    "}\n",
    "\n",
    "# === Feature Functions ===\n",
    "def extract_time_features(signal):\n",
    "    return {\n",
    "        \"mean\": np.mean(signal),\n",
    "        \"variance\": np.var(signal),\n",
    "        \"skewness\": skew(signal),\n",
    "        \"kurtosis\": kurtosis(signal),\n",
    "        \"rms\": np.sqrt(np.mean(signal**2)),\n",
    "        \"zero_crossing_rate\": np.sum(np.diff(np.sign(signal)) != 0) / len(signal),\n",
    "        \"mean_abs\": np.mean(np.abs(signal)),\n",
    "        \"diff_rms1\": np.sqrt(np.mean(np.diff(signal)**2)),\n",
    "        \"diff_rms2\": np.sqrt(np.mean(np.diff(signal, n=2)**2)),\n",
    "    }\n",
    "\n",
    "def extract_frequency_features(signal):\n",
    "    L = len(signal)\n",
    "    Y = np.fft.fft(signal)\n",
    "    P2 = np.abs(Y / L)\n",
    "    P1 = P2[:L // 2 + 1]\n",
    "    P1[1:-1] *= 2\n",
    "    freqs = FS * np.arange(L // 2 + 1) / L\n",
    "\n",
    "    band_power = {band: np.sum(P1[(freqs >= low) & (freqs <= high)]) for band, (low, high) in BANDS.items()}\n",
    "    band_power[\"spectral_entropy\"] = -np.sum(P1 * np.log(P1 + 1e-10))\n",
    "    return band_power\n",
    "\n",
    "def extract_features_from_segment(df):\n",
    "    channel_features = []\n",
    "    for channel in df.columns:\n",
    "        signal = df[channel].values\n",
    "        time_feats = extract_time_features(signal)\n",
    "        freq_feats = extract_frequency_features(signal)\n",
    "        feats = {\"channel\": channel, **time_feats, **freq_feats}\n",
    "        channel_features.append(feats)\n",
    "\n",
    "    df_feats = pd.DataFrame(channel_features)\n",
    "    return df_feats.groupby(\"channel\").mean().reset_index()\n",
    "\n",
    "# === Extract Features from All Files ===\n",
    "all_features = []\n",
    "files = [f for f in os.listdir(PROCESSED_EEG_DIR) if f.endswith(\".parquet\")]\n",
    "\n",
    "for file in tqdm(files, desc=\"Extracting features from preprocessed EEGs\"):\n",
    "    file_path = os.path.join(PROCESSED_EEG_DIR, file)\n",
    "    eeg_id = file.replace(\"_10s.parquet\", \"\")\n",
    "    try:\n",
    "        df = pd.read_parquet(file_path)\n",
    "\n",
    "        # ‚ùå Drop EKG channel if present\n",
    "        if \"EKG\" in df.columns:\n",
    "            df = df.drop(columns=[\"EKG\"])\n",
    "\n",
    "        feats = extract_features_from_segment(df)\n",
    "        feats[\"eeg_id\"] = eeg_id\n",
    "        all_features.append(feats)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed on {file}: {e}\")\n",
    "\n",
    "# === Combine and Save ===\n",
    "if all_features:\n",
    "    final_df = pd.concat(all_features, ignore_index=True)\n",
    "    final_df.to_csv(OUTPUT_FEATURES_CSV, index=False)\n",
    "    print(f\"‚úÖ Saved extracted features to {OUTPUT_FEATURES_CSV}\")\n",
    "else:\n",
    "    print(\"‚ùå No features were extracted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattened data version WORKS\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# === Paths ===\n",
    "FEATURES_PATH = \"C:/Users/Kevin Tran/Documents/Project Data/eeg_extracted_features.csv\"\n",
    "TRAIN_CSV = \"C:/Users/Kevin Tran/Documents/Project Data/train.csv\"\n",
    "OUTPUT_PATH = \"C:/Users/Kevin Tran/Documents/Project Data/eeg_features_flattened_labeled.csv\"\n",
    "\n",
    "# === Load Data ===\n",
    "features_df = pd.read_csv(FEATURES_PATH)\n",
    "train_df = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "# === Clean eeg_id column in features file\n",
    "features_df[\"eeg_id\"] = features_df[\"eeg_id\"].astype(str).str.replace(\"_10s\", \"\", regex=False)\n",
    "train_df[\"eeg_id\"] = train_df[\"eeg_id\"].astype(str)\n",
    "\n",
    "# === Merge only labeled eeg_ids\n",
    "labels_df = train_df[[\"eeg_id\", \"expert_consensus\"]].drop_duplicates()\n",
    "merged = features_df.merge(labels_df, on=\"eeg_id\", how=\"inner\")\n",
    "\n",
    "# === Pivot: Flatten features ‚Üí one row per eeg_id\n",
    "meta_cols = [\"eeg_id\", \"channel\", \"expert_consensus\"]\n",
    "value_cols = [col for col in merged.columns if col not in meta_cols]\n",
    "\n",
    "flattened = merged.pivot_table(index=[\"eeg_id\", \"expert_consensus\"],\n",
    "                                columns=\"channel\",\n",
    "                                values=value_cols)\n",
    "\n",
    "# === Flatten multi-index columns\n",
    "flattened.columns = [f\"{ch}_{feat}\" for feat, ch in flattened.columns]\n",
    "flattened = flattened.reset_index()\n",
    "\n",
    "# === Save\n",
    "flattened.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"‚úÖ Flattened + labeled feature file saved to: {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for something in training\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# === Paths ===\n",
    "INPUT_FLATTENED_CSV = \"C:/Users/Kevin Tran/Documents/Project Data/eeg_features_flattened_labeled.csv\"\n",
    "MODEL_PATH = \"C:/Users/Kevin Tran/Documents/Project Data/random_forest_eeg_model_flat.pkl\"\n",
    "ENCODER_PATH = \"C:/Users/Kevin Tran/Documents/Project Data/label_encoder_flat.pkl\"\n",
    "TRAIN_IDS_PATH = \"C:/Users/Kevin Tran/Documents/Project Data/train_eeg_ids.csv\"\n",
    "TEST_IDS_PATH = \"C:/Users/Kevin Tran/Documents/Project Data/test_eeg_ids.csv\"\n",
    "\n",
    "# === Load Flattened Data ===\n",
    "df = pd.read_csv(INPUT_FLATTENED_CSV)\n",
    "\n",
    "# === Print class distribution\n",
    "print(\"üìä Original Class Distribution:\")\n",
    "print(df[\"expert_consensus\"].value_counts(normalize=True), \"\\n\")\n",
    "\n",
    "# === Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df[\"label_encoded\"] = label_encoder.fit_transform(df[\"expert_consensus\"])\n",
    "\n",
    "# === Split features, target, and IDs\n",
    "eeg_ids = df[\"eeg_id\"]\n",
    "X = df.drop(columns=[\"eeg_id\", \"expert_consensus\", \"label_encoded\"])\n",
    "y = df[\"label_encoded\"]\n",
    "\n",
    "# === Train/Test Split (with IDs)\n",
    "X_train, X_test, y_train, y_test, id_train, id_test = train_test_split(\n",
    "    X, y, eeg_ids, stratify=y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# === Save EEG IDs for later verification\n",
    "pd.Series(id_train).to_csv(TRAIN_IDS_PATH, index=False)\n",
    "pd.Series(id_test).to_csv(TEST_IDS_PATH, index=False)\n",
    "print(f\"üíæ Saved train/test EEG ID lists:\\n- Train: {TRAIN_IDS_PATH}\\n- Test: {TEST_IDS_PATH}\\n\")\n",
    "\n",
    "# === Rebalance Training Set (only)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_balanced, y_train_balanced = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# === Train Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "rf.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# === Evaluate\n",
    "y_pred = rf.predict(X_test)\n",
    "print(\"\\nüìä Classification Report (on test set):\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
    "\n",
    "# === Save Model & Encoder\n",
    "joblib.dump(rf, MODEL_PATH)\n",
    "joblib.dump(label_encoder, ENCODER_PATH)\n",
    "print(f\"\\n‚úÖ Model saved to: {MODEL_PATH}\")\n",
    "print(f\"‚úÖ Label encoder saved to: {ENCODER_PATH}\")\n",
    "\n",
    "# === Plot Feature Importances\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[-20:]  # Top 20\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"üîç Top 20 Feature Importances\")\n",
    "plt.barh(range(len(indices)), importances[indices], align=\"center\")\n",
    "plt.yticks(range(len(indices)), [X.columns[i] for i in indices])\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattened cleaned up\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt, iirnotch\n",
    "import joblib\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# === Suppress clutter ===\n",
    "mne.set_log_level(\"WARNING\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# === Paths ===\n",
    "INPUT_DIR = \"C:/Users/Kevin Tran/Documents/Project Data/Input files\"\n",
    "MODEL_PATH = \"C:/Users/Kevin Tran/Documents/Project Data/random_forest_eeg_model_flat.pkl\"\n",
    "ENCODER_PATH = \"C:/Users/Kevin Tran/Documents/Project Data/label_encoder_flat.pkl\"\n",
    "OUTPUT_CSV = \"C:/Users/Kevin Tran/Documents/Project Data/eeg_predictions_flat.csv\"\n",
    "FS = 200  # Hz\n",
    "\n",
    "# === EEG Frequency Bands ===\n",
    "BANDS = {\n",
    "    \"delta\": (1, 3), \"theta\": (4, 7), \"alpha1\": (8, 9), \"alpha2\": (10, 12),\n",
    "    \"beta1\": (13, 17), \"beta2\": (18, 30), \"gamma1\": (31, 40),\n",
    "    \"gamma2\": (41, 50), \"higher\": (51, 100)\n",
    "}\n",
    "\n",
    "# === Preprocessing ===\n",
    "def apply_notch_filter(signal):\n",
    "    b, a = iirnotch(w0=60.0, Q=30, fs=FS)\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "def apply_bandpass_filter(signal):\n",
    "    nyq = 0.5 * FS\n",
    "    low, high = 0.5 / nyq, 40.0 / nyq\n",
    "    b, a = butter(5, [low, high], btype='band')\n",
    "    return filtfilt(b, a, signal)\n",
    "\n",
    "def normalize_signal(signal):\n",
    "    return (signal - np.mean(signal)) / np.std(signal)\n",
    "\n",
    "def apply_ica(df):\n",
    "    try:\n",
    "        n_components = min(10, len(df.columns))\n",
    "        info = mne.create_info(ch_names=list(df.columns), sfreq=FS, ch_types=[\"eeg\"] * len(df.columns))\n",
    "        raw = mne.io.RawArray(df.values.T, info)\n",
    "        raw.filter(l_freq=1.0, h_freq=None)\n",
    "        ica = mne.preprocessing.ICA(n_components=n_components, random_state=42, max_iter=\"auto\")\n",
    "        ica.fit(raw)\n",
    "        raw_clean = ica.apply(raw)\n",
    "        return pd.DataFrame(raw_clean.get_data().T, columns=df.columns)\n",
    "    except Exception:\n",
    "        return df\n",
    "\n",
    "# === Feature Extraction ===\n",
    "def extract_time_features(signal):\n",
    "    return {\n",
    "        \"mean\": np.mean(signal),\n",
    "        \"variance\": np.var(signal),\n",
    "        \"skewness\": skew(signal),\n",
    "        \"kurtosis\": kurtosis(signal),\n",
    "        \"rms\": np.sqrt(np.mean(signal**2)),\n",
    "        \"zero_crossing_rate\": np.sum(np.diff(np.sign(signal)) != 0) / len(signal),\n",
    "        \"mean_abs\": np.mean(np.abs(signal)),\n",
    "        \"diff_rms1\": np.sqrt(np.mean(np.diff(signal)**2)),\n",
    "        \"diff_rms2\": np.sqrt(np.mean(np.diff(signal, n=2)**2)),\n",
    "    }\n",
    "\n",
    "def extract_frequency_features(signal):\n",
    "    L = len(signal)\n",
    "    Y = np.fft.fft(signal)\n",
    "    P2 = np.abs(Y / L)\n",
    "    P1 = P2[:L // 2 + 1]\n",
    "    P1[1:-1] *= 2\n",
    "    freqs = FS * np.arange(L // 2 + 1) / L\n",
    "    band_power = {band: np.sum(P1[(freqs >= low) & (freqs <= high)]) for band, (low, high) in BANDS.items()}\n",
    "    band_power[\"spectral_entropy\"] = -np.sum(P1 * np.log(P1 + 1e-10))\n",
    "    return band_power\n",
    "\n",
    "def extract_flattened_features(df):\n",
    "    all_feats = {}\n",
    "    for ch in df.columns:\n",
    "        signal = df[ch].values\n",
    "        tf = extract_time_features(signal)\n",
    "        ff = extract_frequency_features(signal)\n",
    "        for k, v in {**tf, **ff}.items():\n",
    "            all_feats[f\"{ch}_{k}\"] = v\n",
    "    return pd.DataFrame([all_feats])\n",
    "\n",
    "# === Load Model & Encoder\n",
    "model = joblib.load(MODEL_PATH)\n",
    "encoder = joblib.load(ENCODER_PATH)\n",
    "\n",
    "# === Collect files\n",
    "all_files = sorted([\n",
    "    f for f in os.listdir(INPUT_DIR)\n",
    "    if f.endswith(\".parquet\") and not f.startswith(\"~\") and not f.startswith(\".\")\n",
    "])\n",
    "print(f\"üìÇ Found {len(all_files)} valid EEG files to process.\\n\")\n",
    "\n",
    "# === Prediction Loop\n",
    "results = []\n",
    "for fname in tqdm(all_files, desc=\"Predicting\"):\n",
    "    fpath = os.path.join(INPUT_DIR, fname)\n",
    "    try:\n",
    "        df = pd.read_parquet(fpath)\n",
    "\n",
    "        # Drop EKG if present\n",
    "        if \"EKG\" in df.columns:\n",
    "            df = df.drop(columns=[\"EKG\"])\n",
    "\n",
    "        if len(df) < 30 * FS:\n",
    "            print(f\"‚ö†Ô∏è Skipping {fname}: too short\")\n",
    "            continue\n",
    "\n",
    "        # Extract center 10s segment\n",
    "        segment = df.iloc[20 * FS : 30 * FS].copy()\n",
    "\n",
    "        for ch in segment.columns:\n",
    "            segment[ch] = normalize_signal(apply_bandpass_filter(apply_notch_filter(segment[ch].values)))\n",
    "\n",
    "        segment = apply_ica(segment)\n",
    "        features = extract_flattened_features(segment)\n",
    "\n",
    "        # Ensure matching feature names\n",
    "        for col in model.feature_names_in_:\n",
    "            if col not in features.columns:\n",
    "                features[col] = 0.0\n",
    "        features = features[model.feature_names_in_]\n",
    "\n",
    "        # Predict\n",
    "        pred = model.predict(features)[0]\n",
    "        label = encoder.inverse_transform([pred])[0]\n",
    "\n",
    "        print(f\"üß† {fname} ‚Üí Predicted: {label}\")\n",
    "        results.append({\"eeg_file\": fname, \"prediction\": label})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {fname}: {e}\")\n",
    "        results.append({\"eeg_file\": fname, \"prediction\": \"Error\"})\n",
    "\n",
    "# === Save Predictions\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"\\n‚úÖ All predictions saved to: {OUTPUT_CSV}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
